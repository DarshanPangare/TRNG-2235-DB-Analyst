{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "001cb229-aadd-4f43-82b0-923be5ab32e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Delta Lake & Data Ingestion\n",
    "\n",
    "- Getting data into databricks is comonly called data ingestion.\n",
    "- data engineers or data warehouse managers are primarily responsible for data ingestion.\n",
    "\n",
    "### Delta Lake\n",
    "\n",
    "![delta lake](./images/delta-lake.png)\n",
    "\n",
    "- the goal of data ingestion is to bring in files and data from external data sourceslike cloud storage and sql tables inro Delta Lake as Delta tabels.\n",
    "- Delta Lake is an open-source protocol that databricks uses for the data layer.\n",
    "\n",
    "\n",
    "### Delta Table\n",
    "\n",
    "\n",
    "- Delta tables store data within a folder directory. Within that directory the data is stored as **Parquet files** .\n",
    "- Delta adds delta logs that are stored as JSON files alogside the parquet files.\n",
    "- delta logs keep track of all transactions on data and table versions.\n",
    "- table states are maintained using the transaction logs. If data is inserted, deleted or updated in the table, Delta adds a transaction (log file) and the table stays updated and managed.\n",
    "\n",
    "- The transaction log provides:\n",
    "\n",
    "  - **ACID transactions** (atomicity, consistency, isolation, durability) for concurrent reads/writes.\n",
    "  - **Table versioning** enabling **time travel** (querying historical data).\n",
    "  \n",
    "\n",
    "### Key Features of Delta Lake\n",
    "\n",
    "* ACID transaction support for safe concurrent operations.\n",
    "* DML operations (INSERT, UPDATE, DELETE, MERGE).\n",
    "* Time travel to query or restore previous versions.\n",
    "* Schema enforcement and evolution.\n",
    "* Unified batch and streaming support.\n",
    "* Optimizations and scalability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36cb1f26-0ff3-4930-b784-91400159ff04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "USE CATALOG workspace;\n",
    "USE SCHEMA `2235-wk3`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ee9ddcc-9798-41bc-804d-96a43dd5f7d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT current_catalog(), current_schema();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffc65044-c722-4cfa-9097-48be5fe81def",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Common Data Importing Methods for Data Analysts:**\n",
    "\n",
    "- File Upload UI\n",
    "\n",
    "- CTAS (Creat table as Select)\n",
    "\n",
    "- COPY INTO \n",
    "\n",
    "- FROM read_files()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfa067dc-357a-46ef-a0b0-a69c932a6665",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Ingestion with CTAS and read_files() - BATCH Ingestion\n",
    "\n",
    "- `CREATE TABLE AS (CTAS)` is used to create and populate tables using the results of a query.\n",
    "- `read_files()` table-valued function enebles reading data of various file formats and provides additional options for data ingestion.\n",
    "\n",
    "**Documentation:**\n",
    "\n",
    "- [read_files](https://docs.databricks.com/aws/en/sql/language-manual/functions/read_files)\n",
    "\n",
    "\n",
    "**Note:**\n",
    "\n",
    "- a `_rescued_data` column is automatically added to capture any data that does not match the inferred schema.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "614a51c5-d9c9-4637-a3e4-f02eda90fbca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh \n",
    "\n",
    "ls /Volumes/workspace/2235-wk3/orders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "075bb248-2e1d-4afa-acee-9056b9b325c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM csv.`/Volumes/workspace/2235-wk3/orders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "604c7f29-1d32-435d-8e6c-030192a20921",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM \n",
    "\n",
    "read_files(\n",
    "\n",
    "  '/Volumes/workspace/2235-wk3/orders',\n",
    "  format => 'csv',\n",
    "  inferSchema => 'true',\n",
    "  header => 'true',\n",
    "  escape => '\"'\n",
    ") LIMIT  10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0443c094-bc77-4677-a9f9-03721234dd7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE TABLE orders_bronze\n",
    "USING DELTA -- optional\n",
    "SELECT * FROM \n",
    "read_files(\n",
    "\n",
    "  '/Volumes/workspace/2235-wk3/orders',\n",
    "  format => 'csv',\n",
    "  inferSchema => 'true',\n",
    "  header => 'true',\n",
    "  escape => '\"'\n",
    ");\n",
    "\n",
    "-- preview the table\n",
    "\n",
    "SELECT * FROM orders_bronze;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bfc8b54-ad34-4bd9-aba4-bbdf4e7feace",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DESCRIBE TABLE orders_bronze;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb10c0e6-064a-4e48-b2f0-26b7a3bb923a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DESCRIBE TABLE EXTENDED orders_bronze;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75c085af-d416-4679-8c36-74be5bfe909c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### tabels\n",
    "\n",
    "- managed table - UC manages everything; even cloud storage.\n",
    "  - discards metadata and deletes the associated data when table is dropped\n",
    "  - format is delta\n",
    "  - comes with new features, performance, simplicity, stricter access\n",
    "- external table - external cloud location\n",
    "  - discards meteadata only. does not dete the data\n",
    "  - the path specified bt the `LOCATION` keyword\n",
    "  - manually manages\n",
    "  - format can be DELTA, CSV, JSON, AVRO, and PARQUET etc.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f05cbf6-af70-435d-8a2c-9799f46a2069",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "184bf166-23a0-469f-b11b-94177e1dbc45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "df = (spark.read.format(\"csv\").load(\"/Volumes/workspace/2235-wk3/orders\", header = True, inferSchema = True, escape = '\"'))\n",
    "\n",
    "(df.write.mode(\"overwrite\").saveAsTable(\"orders_bronze_py\"))\n",
    "\n",
    "orders_bronze = spark.table(\"orders_bronze_py\")\n",
    "\n",
    "orders_bronze.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9712f00c-5f5f-472c-b370-424ac23ec560",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Data Ingestion using COPY INTO - Incremental data ingestion\n",
    "\n",
    "- `COPY INTO` allows to load data from a file location into Delta table. \n",
    "- re-triable and idempotent.\n",
    "- new files in source location are added and files already loaded are skipped.\n",
    "\n",
    "**Documentation**\n",
    "\n",
    "[COPY INTO](https://docs.databricks.com/aws/en/sql/language-manual/delta-copy-into)\n",
    "\n",
    "\n",
    "- `mergeSchema` copy option is used for schema evolution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d313f609-9da0-485b-8f86-60b6d7ab9343",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DROP TABLE IF EXISTS orders_bronze_ci;\n",
    "CREATE TABLE orders_bronze_ci;\n",
    "\n",
    "COPY INTO orders_bronze_ci\n",
    "FROM '/Volumes/workspace/2235-wk3/orders'\n",
    "FILEFORMAT = CSV\n",
    "FORMAT_OPTIONS ('header' = 'true', 'escape' = '\"')\n",
    "COPY_OPTIONS ('mergeSchema' = 'true');\n",
    "\n",
    "\n",
    "SELECT * FROM orders_bronze_ci;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecc0cc97-6109-4400-8465-112c3e74e223",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1754937753113}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "COPY INTO orders_bronze_ci\n",
    "FROM '/Volumes/workspace/2235-wk3/orders'\n",
    "FILEFORMAT = CSV\n",
    "FORMAT_OPTIONS ('header' = 'true', 'escape' = '\"')\n",
    "COPY_OPTIONS ('mergeSchema' = 'true');\n",
    "\n",
    "\n",
    "-- SELECT * FROM orders_bronze_ci;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d40493c-b481-4bad-9452-5c673a9b7007",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6721217452831257,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01-databricks-data-ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
